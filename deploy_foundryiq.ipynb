{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["# üöÄ FoundryIQ Deployment Notebook\n\nThis notebook enables deploying the FoundryIQ AI Document Assistant directly from **GitHub Codespaces**.\n\n## What This Notebook Does\n\n1. **Logs into Azure** - Using device code flow\n2. **Installs dependencies** - Azure SDK, OpenAI client\n3. **Discovers Azure resources** - Finds AI Services and Search\n4. **Creates Azure AI Search index** - With vector search\n5. **Processes documents** - From `/files` folder\n6. **Indexes documents** - Generates embeddings\n7. **Tests the system** - With sample queries\n\n---\n\n**Run each cell in order using `Shift+Enter`.**"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## 1Ô∏è‚É£ Install Required Dependencies"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["import subprocess, sys\n\npackages = [\"azure-identity\", \"azure-search-documents\", \"openai\", \"python-dotenv\", \"pandas\", \"openpyxl\", \"python-docx\", \"PyPDF2\"]\n\nprint(\"üì¶ Installing dependencies...\")\nfor pkg in packages:\n    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg])\nprint(\"‚úÖ Done!\")"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## 2Ô∏è‚É£ Login to Azure\n\nUses **device code flow** which works in GitHub Codespaces."]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["import subprocess, os, json\n\ndef check_login():\n    try:\n        r = subprocess.run([\"az\", \"account\", \"show\", \"--query\", \"user.name\", \"-o\", \"tsv\"], capture_output=True, text=True, timeout=10)\n        return r.stdout.strip() if r.returncode == 0 else None\n    except: return None\n\nuser = check_login()\nif user:\n    print(f\"‚úÖ Logged in as: {user}\")\nelse:\n    print(\"üîê Starting Azure login...\")\n    subprocess.run([\"az\", \"login\", \"--use-device-code\"])"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["### Select Subscription"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["subs = json.loads(subprocess.run([\"az\", \"account\", \"list\", \"-o\", \"json\"], capture_output=True, text=True).stdout)\nprint(\"üìã Subscriptions:\")\nfor i, s in enumerate(subs):\n    print(f\"  [{i+1}] {s['name']}\" + (\" ‚Üê CURRENT\" if s.get('isDefault') else \"\"))\n\n# Set SUBSCRIPTION_INDEX to change (e.g., 1, 2, 3)\nSUBSCRIPTION_INDEX = None\nif SUBSCRIPTION_INDEX:\n    subprocess.run([\"az\", \"account\", \"set\", \"--subscription\", subs[SUBSCRIPTION_INDEX-1]['id']])"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## 3Ô∏è‚É£ Discover Azure Resources"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["from dotenv import load_dotenv\nload_dotenv('.env') if os.path.exists('.env') else None\n\nconfig = {\n    \"AZURE_OPENAI_ENDPOINT\": os.getenv(\"AZURE_OPENAI_ENDPOINT\", \"\"),\n    \"AZURE_OPENAI_API_KEY\": os.getenv(\"AZURE_OPENAI_API_KEY\", \"\"),\n    \"AZURE_OPENAI_DEPLOYMENT\": os.getenv(\"AZURE_OPENAI_DEPLOYMENT\", \"gpt-4.1\"),\n    \"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\": os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\", \"text-embedding-3-small\"),\n    \"AZURE_SEARCH_ENDPOINT\": os.getenv(\"AZURE_SEARCH_ENDPOINT\", \"\"),\n    \"AZURE_SEARCH_API_KEY\": os.getenv(\"AZURE_SEARCH_API_KEY\", \"\"),\n    \"AZURE_SEARCH_INDEX_NAME\": os.getenv(\"AZURE_SEARCH_INDEX_NAME\", \"foundryiq-documents\"),\n}\n\nprint(\"üîç Discovering resources...\")\nai_svc = json.loads(subprocess.run([\"az\", \"cognitiveservices\", \"account\", \"list\", \"--query\", \"[?kind=='AIServices'||kind=='OpenAI'].{name:name,endpoint:properties.endpoint,rg:resourceGroup}\", \"-o\", \"json\"], capture_output=True, text=True).stdout or '[]')\nsearch_svc = json.loads(subprocess.run([\"az\", \"resource\", \"list\", \"--resource-type\", \"Microsoft.Search/searchServices\", \"--query\", \"[].{name:name,rg:resourceGroup}\", \"-o\", \"json\"], capture_output=True, text=True).stdout or '[]')\n\nprint(f\"ü§ñ AI Services: {[s['name'] for s in ai_svc]}\")\nprint(f\"üîé Search: {[s['name'] for s in search_svc]}\")"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["### Select Resources"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["OPENAI_INDEX, SEARCH_INDEX = 1, 1\n\nif ai_svc:\n    sel = ai_svc[OPENAI_INDEX-1]\n    config[\"AZURE_OPENAI_ENDPOINT\"] = sel.get(\"endpoint\", \"\")\n    config[\"AZURE_OPENAI_API_KEY\"] = subprocess.run([\"az\", \"cognitiveservices\", \"account\", \"keys\", \"list\", \"--name\", sel[\"name\"], \"--resource-group\", sel[\"rg\"], \"--query\", \"key1\", \"-o\", \"tsv\"], capture_output=True, text=True).stdout.strip()\n    print(f\"‚úÖ AI Service: {sel['name']}\")\n\nif search_svc:\n    sel = search_svc[SEARCH_INDEX-1]\n    config[\"AZURE_SEARCH_ENDPOINT\"] = f\"https://{sel['name']}.search.windows.net\"\n    config[\"AZURE_SEARCH_API_KEY\"] = subprocess.run([\"az\", \"search\", \"admin-key\", \"show\", \"--service-name\", sel[\"name\"], \"--resource-group\", sel[\"rg\"], \"--query\", \"primaryKey\", \"-o\", \"tsv\"], capture_output=True, text=True).stdout.strip()\n    print(f\"‚úÖ Search: {sel['name']}\")\n\nwith open('.env', 'w') as f:\n    for k, v in config.items(): f.write(f\"{k}={v}\\n\")\nprint(\"üíæ Saved to .env\")"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## 4Ô∏è‚É£ Create Search Index"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["from azure.search.documents.indexes import SearchIndexClient\nfrom azure.search.documents.indexes.models import SearchIndex, SearchField, SearchFieldDataType, VectorSearch, HnswAlgorithmConfiguration, VectorSearchProfile, SearchableField, SimpleField\nfrom azure.core.credentials import AzureKeyCredential\n\nindex_client = SearchIndexClient(config[\"AZURE_SEARCH_ENDPOINT\"], AzureKeyCredential(config[\"AZURE_SEARCH_API_KEY\"]))\nindex_name = config[\"AZURE_SEARCH_INDEX_NAME\"]\n\ntry:\n    index_client.get_index(index_name)\n    print(f\"‚úÖ Index '{index_name}' exists\")\nexcept:\n    fields = [\n        SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True),\n        SearchableField(name=\"content\", type=SearchFieldDataType.String),\n        SearchableField(name=\"title\", type=SearchFieldDataType.String),\n        SimpleField(name=\"file_name\", type=SearchFieldDataType.String, filterable=True),\n        SearchField(name=\"content_vector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single), searchable=True, vector_search_dimensions=1536, vector_search_profile_name=\"vector-profile\")\n    ]\n    vs = VectorSearch(algorithms=[HnswAlgorithmConfiguration(name=\"hnsw\")], profiles=[VectorSearchProfile(name=\"vector-profile\", algorithm_configuration_name=\"hnsw\")])\n    index_client.create_index(SearchIndex(name=index_name, fields=fields, vector_search=vs))\n    print(f\"‚úÖ Created '{index_name}'\")\n"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## 5Ô∏è‚É£ Process Documents"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["import pandas as pd, hashlib\nfrom pathlib import Path\n\ndef read_file(path):\n    docs, name, suffix = [], Path(path).name, Path(path).suffix.lower()\n    try:\n        if suffix == '.csv':\n            for i, row in pd.read_csv(path).iterrows():\n                docs.append({\"id\": hashlib.md5(f\"{name}_{i}\".encode()).hexdigest(), \"content\": \" | \".join([f\"{c}: {v}\" for c,v in row.items() if pd.notna(v)]), \"title\": f\"{name} - Row {i+1}\", \"file_name\": name})\n        elif suffix in ['.xlsx', '.xls']:\n            for i, row in pd.read_excel(path).iterrows():\n                docs.append({\"id\": hashlib.md5(f\"{name}_{i}\".encode()).hexdigest(), \"content\": \" | \".join([f\"{c}: {v}\" for c,v in row.items() if pd.notna(v)]), \"title\": f\"{name} - Row {i+1}\", \"file_name\": name})\n    except Exception as e: print(f\"‚ö†Ô∏è {name}: {e}\")\n    return docs\n\nall_docs = []\nfor f in Path('files').iterdir():\n    if not f.name.startswith('.'):\n        docs = read_file(str(f))\n        if docs: all_docs.extend(docs); print(f\"‚úÖ {f.name}: {len(docs)}\")\nprint(f\"üìä Total: {len(all_docs)} chunks\")"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## 6Ô∏è‚É£ Generate Embeddings & Index"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["from openai import AzureOpenAI\nfrom azure.search.documents import SearchClient\n\noai = AzureOpenAI(api_key=config[\"AZURE_OPENAI_API_KEY\"], api_version=\"2024-08-01-preview\", azure_endpoint=config[\"AZURE_OPENAI_ENDPOINT\"])\n\nprint(\"üß† Generating embeddings...\")\nfor i in range(0, len(all_docs), 16):\n    batch = all_docs[i:i+16]\n    resp = oai.embeddings.create(input=[d[\"content\"][:8000] for d in batch], model=config[\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\"])\n    for j, item in enumerate(resp.data): batch[j][\"content_vector\"] = item.embedding\n    print(f\"  Batch {i//16+1}\")\n\nprint(\"üì§ Uploading...\")\nsc = SearchClient(config[\"AZURE_SEARCH_ENDPOINT\"], config[\"AZURE_SEARCH_INDEX_NAME\"], AzureKeyCredential(config[\"AZURE_SEARCH_API_KEY\"]))\nfor i in range(0, len(all_docs), 100):\n    sc.upload_documents(all_docs[i:i+100])\nprint(\"‚úÖ Done!\")"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## 7Ô∏è‚É£ Test"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["from azure.search.documents.models import VectorizedQuery\n\ndef ask(q):\n    vec = oai.embeddings.create(input=[q], model=config[\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\"]).data[0].embedding\n    results = list(sc.search(search_text=q, vector_queries=[VectorizedQuery(vector=vec, k_nearest_neighbors=5, fields=\"content_vector\")], top=5))\n    ctx = \"\\n\".join([f\"[{r['title']}]: {r['content'][:300]}\" for r in results])\n    return oai.chat.completions.create(model=config[\"AZURE_OPENAI_DEPLOYMENT\"], messages=[{\"role\": \"system\", \"content\": \"Answer based on context.\"}, {\"role\": \"user\", \"content\": f\"Context:\\n{ctx}\\n\\nQ: {q}\"}]).choices[0].message.content\n\nprint(\"üß™ Testing...\")\nfor q in [\"What products are available?\", \"Customer status overview?\"]:\n    print(f\"‚ùì {q}\\nüí¨ {ask(q)}\\n\")"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## ‚úÖ Complete!\n\nNext steps:\n- `python -m uvicorn src.api:app --reload`\n- `cd frontend && npm run dev`"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["# Interactive - change question and re-run\nYOUR_QUESTION = \"Executive summary of operational health\"\nprint(f\"üí¨ {ask(YOUR_QUESTION)}\")"]
    }
  ],
  "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.10.0"}},
  "nbformat": 4,
  "nbformat_minor": 5
}
